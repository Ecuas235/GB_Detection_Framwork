{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "from datasets import Dataset\n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY2\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Game Bot Detection Framework\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_index(player_df, embedding_file=\"../model/player_embeddings_4000.npy\"):\n",
    "    \"\"\"Loads pre-computed embeddings from a pickle file and builds FAISS index.\"\"\"\n",
    "    try:\n",
    "        # with open(embedding_file, \"rb\") as f:\n",
    "        #     embeddings = pickle.load(f)\n",
    "        embeddings = np.load(embedding_file)\n",
    "        player_ids = player_df['Actor'].astype(str).tolist()\n",
    "        # Ensure loaded embeddings are a numpy array and have the correct shape\n",
    "        if isinstance(embeddings, list):\n",
    "            embeddings = np.array(embeddings).astype('float32')  # Convert to numpy array\n",
    "        if isinstance(embeddings, tuple):\n",
    "            print(\"Tuple detected. Converting the embeddings to numpy array\")\n",
    "            embeddings = np.array(embeddings).astype('float32') \n",
    "        if not isinstance(embeddings, np.ndarray):\n",
    "            raise ValueError(\"Loaded embeddings are not a numpy array.\")\n",
    "\n",
    "        if len(embeddings.shape) != 2:\n",
    "            raise ValueError(f\"Embeddings must be 2D array, got shape {embeddings.shape}\")\n",
    "\n",
    "        # Build FAISS index\n",
    "        dimension = embeddings.shape[1]\n",
    "        faiss_index = faiss.IndexFlatL2(dimension)\n",
    "        faiss_index.add(embeddings)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Embedding file not found at {embedding_file}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading and building FAISS index: {e}\")\n",
    "        raise\n",
    "    return faiss_index\n",
    "def get_embedding_for_player(player_id: str, embedding_file=\"../model/player_embeddings_4000.npy\"):\n",
    "    \"\"\"\n",
    "    Retrieves the pre-computed embedding for a specific player from the embeddings file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        embeddings = np.load(embedding_file)\n",
    "        player_df = pd.read_csv('../../data/sample/sample_player_data.csv')\n",
    "        player_ids = player_df['Actor'].astype(str).tolist()\n",
    "\n",
    "        player_index = player_ids.index(player_id)\n",
    "        return np.array(embeddings[player_index]).astype('float32')\n",
    "    except ValueError:\n",
    "        print(f\"Player ID {player_id} not found in embeddings.\")\n",
    "        return None\n",
    "    except FileNotFoundError:\n",
    "            print(f\"Error: Embedding file not found at {embedding_file}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading embeddings: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml/anomaly_scoring_agent.py\n",
    "import os\n",
    "from typing import List\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "# Initialize LLM and Neo4j Graph\n",
    "llm = ChatGroq(model=\"llama-3.3-70b-versatile\")\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD\n",
    ")\n",
    "\n",
    "# ml/prompts.py\n",
    "def anomaly_scoring_prompt():\n",
    "    return \"\"\"\n",
    "<|system|>\n",
    "You are an expert game analyst tasked with identifying bots in an online game by analyzing player statistics. Your role is to generate an anomaly score (0-100, higher score means more likely to be a bot) and provide concise reasoning based on the player data.\n",
    "\n",
    "Here is how to interpret each player statistic. Provide context for how each statistic informs your score. Focus on how these characteristics point to a bot.\n",
    "\n",
    "- **Actor**: The player's unique identifier.\n",
    "- **A_Acc**: Account ID of the player; may provide clues about account creation patterns.\n",
    "- **Login_day_count**: Number of distinct days the player has logged in. Focus on if low compared to other statitics, this will indicate bot behaviour.\n",
    "- **Logout_day_count**: Number of days the player logged out. Should closely align with login days; inconsistencies could be a sign.\n",
    "- **Playtime**: Total playtime in seconds. An unusually high total compared to login days could signal a bot farming.\n",
    "- **playtime_per_day**: Average playtime per day in seconds. High values here are key identifiers of 24/7 bots.\n",
    "- **avg_money**: Average amount of in-game currency. Focus on this, as extreme values here could mean exploits or excessive farming.\n",
    "- **Login_count**: Total number of logins; high activity would indicate a bot constantly repeating logins.\n",
    "- **ip_count**: Number of unique IP addresses used. A very low counts or a high could signal an anomaly\n",
    "- **Max_level**: Maximum level achieved by the player. This, with the above information would provide an indicator on its anomaly.\n",
    "\n",
    "Consider:\n",
    "\n",
    "1.  Is the \"Login_day_count\" very low, which would indicate little human input.\n",
    "2.  Examine Playtime, playtime_per_day, and avg_money to uncover indications of farming or exploiting.\n",
    "3. Look at the ip_count. An extremely large number or low number would indicate bot behaviour\n",
    "\n",
    "Based on those descriptions, you will be given the following information and need to determine these two things\n",
    "\n",
    "1.  Determine the **anomaly score** (0-100): A higher score indicates a greater likelihood of the player being a bot. This MUST be provided\n",
    "\n",
    "2.  Provide a **detailed explanation** of your reasoning. This MUST be provided\n",
    "\n",
    "Your final output **MUST** follow this structure:\n",
    "\n",
    "Anomaly Score: [your anomaly score 0-100]\n",
    "Reasoning: [Your reasoning based on patterns from the statistics. Be as clear as possible]\n",
    "\n",
    "Respond concisely and directly.\n",
    "\n",
    "<|user|>\n",
    "Here is the player data:\n",
    "\n",
    "Actor: {actor}\n",
    "A_Acc: {a_acc}\n",
    "Login_day_count: {login_day_count}\n",
    "Logout_day_count: {logout_day_count}\n",
    "Playtime: {playtime}\n",
    "playtime_per_day: {playtime_per_day}\n",
    "avg_money: {avg_money}\n",
    "Login_count: {login_count}\n",
    "ip_count: {ip_count}\n",
    "Max_level: {max_level}\n",
    "\n",
    "Anomaly Score:\n",
    "Reasoning:\n",
    "\"\"\"\n",
    "def extract_player_features(player_id: str) -> dict:\n",
    "    \"\"\"Extracts features from the knowledge graph for a given player.\"\"\"\n",
    "    query = f\"\"\"\n",
    "    MATCH (p:Player {{Actor: toInteger('{player_id}')}})\n",
    "    RETURN\n",
    "        p.Actor AS player_id,\n",
    "        p.A_Acc AS a_acc,\n",
    "        p.Login_day_count AS login_day_count,\n",
    "        p.Logout_day_count AS logout_day_count,\n",
    "        p.Playtime AS playtime,\n",
    "        p.playtime_per_day AS playtime_per_day,\n",
    "        p.avg_money AS avg_money,\n",
    "        p.Login_count AS login_count,\n",
    "        p.ip_count AS ip_count,\n",
    "        p.Max_level AS max_level\n",
    "    \"\"\"\n",
    "    results = graph.query(query)\n",
    "    if results:\n",
    "        return results[0]\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "prompt_template = anomaly_scoring_prompt()\n",
    "\n",
    "if prompt_template:\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "else:\n",
    "    prompt = None  # Handle the case where the prompt couldn't be loaded\n",
    "\n",
    "def assess_bot_likelihood(player_data: dict, similar_player_ids: List[str] = []) -> tuple[int, str, str]:\n",
    "    \"\"\"Assesses the likelihood of a player being a bot using LLM, considering player statistics and insights from similar players.\"\"\"\n",
    "    if prompt is None:\n",
    "        return None, \"Prompt could not be loaded\", None\n",
    "\n",
    "    # Get insights from similar players\n",
    "    similar_player_insights = \"\"\n",
    "    if similar_player_ids:\n",
    "        similar_player_data = [extract_player_features(pid) for pid in similar_player_ids]\n",
    "        # Combine insights (e.g., summarize their behaviors or anomaly scores)\n",
    "        similar_player_insights = f\"Similar players: {', '.join(similar_player_ids)}. \" \\\n",
    "                                  f\"Insights: {similar_player_data}\"  # Simple concatenation for now\n",
    "\n",
    "    # Format the prompt\n",
    "    formatted_prompt = prompt.format_messages(\n",
    "        actor=player_data['player_id'],\n",
    "        a_acc=player_data['a_acc'],\n",
    "        login_day_count=player_data['login_day_count'],\n",
    "        logout_day_count=player_data['logout_day_count'],\n",
    "        playtime=player_data['playtime'],\n",
    "        playtime_per_day=player_data['playtime_per_day'],\n",
    "        avg_money=player_data['avg_money'],\n",
    "        login_count=player_data['login_count'],\n",
    "        ip_count=player_data['ip_count'],\n",
    "        max_level=player_data['max_level'],\n",
    "        similar_player_insights=similar_player_insights  # Pass insights\n",
    "    )\n",
    "\n",
    "    # Call the LLM directly\n",
    "    response = llm.invoke(formatted_prompt)\n",
    "    full_analysis = response.content\n",
    "\n",
    "    # Extract Anomaly Score and Reasoning\n",
    "    try:\n",
    "        score_line = next(line for line in full_analysis.split('\\n') if \"Anomaly Score\" in line)\n",
    "        anomaly_score = int(score_line.split(\":\")[1].strip())\n",
    "\n",
    "        reasoning = \"\\n\".join(full_analysis.split('\\n')[1:])  # All lines after the score\n",
    "    except Exception as e:\n",
    "            anomaly_score = None\n",
    "            reasoning = f\"Could not reliably parse LLM response: {str(e)}\"\n",
    "\n",
    "    return anomaly_score, reasoning, full_analysis\n",
    "\n",
    "def generate_bot_report(player_ids: list[str], faiss_index) -> list[dict]:\n",
    "    \"\"\"Generates a report for a list of player IDs, incorporating insights from semantically similar players.\"\"\"\n",
    "    report = []\n",
    "    for player_id in player_ids:\n",
    "        player_data = extract_player_features(player_id)\n",
    "        if player_data:\n",
    "            # Get the player embedding (Assuming 1-1 correspondence between player_id and embeddings)\n",
    "            try:\n",
    "                query_embedding = get_embedding_for_player(player_id)\n",
    "\n",
    "                if query_embedding is None:\n",
    "                    print(f\"No embedding found for player ID: {player_id}\")\n",
    "                    continue # Skip to the next player\n",
    "\n",
    "                similar_player_ids = None\n",
    "\n",
    "                anomaly_score, reasoning, full_analysis = assess_bot_likelihood(player_data, similar_player_ids)  # Pass similar IDs\n",
    "\n",
    "                report.append({\n",
    "                    \"player_id\": player_id,\n",
    "                    \"anomaly_score\": anomaly_score,\n",
    "                    \"reasoning\": reasoning,\n",
    "                    \"full_analysis\": full_analysis,\n",
    "                    \"similar_player_ids\": similar_player_ids,\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating report for player {player_id}: {e}\")\n",
    "                # You might want to continue to the next player or re-raise the exception\n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_df = pd.read_csv('../../data/sample/sample_player_data.csv')\n",
    "if evaluation_df is None:\n",
    "    print(\"Evaluation data loading failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_ragas_dataset(evaluation_df):\n",
    "    ragas_data = []\n",
    "    for _, row in tqdm(evaluation_df.iterrows()):\n",
    "        player_info = f\"Actor: {row['Actor']}, A_Acc: {row['A_Acc']}, Login_day_count: {row['Login_day_count']}, Logout_day_count: {row['Logout_day_count']}, Playtime: {row['Playtime']}, playtime_per_day: {row['playtime_per_day']}, avg_money: {row['avg_money']}, Login_count: {row['Login_count']}, ip_count: {row['ip_count']}, Max_level: {row['Max_level']}\"\n",
    "        faiss_index = load_index(evaluation_df)\n",
    "        # Generate bot report for this player\n",
    "        bot_report = generate_bot_report([str(row['Actor'])], faiss_index)[0]\n",
    "        \n",
    "        ragas_data.append({\n",
    "            \"user_input\": f\"Analyze the following player data and determine if it's likely a bot: {player_info}\",\n",
    "            \"retrieved_contexts\": player_info,\n",
    "            \"response\": f\"Anomaly Score: {bot_report['anomaly_score']}\\nReasoning: {bot_report['reasoning']}\",\n",
    "            \"reference\": f\"Type: {row['Type']}\"  # Assuming 'Type' indicates bot or human\n",
    "        })\n",
    "    return ragas_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_df = evaluation_df.iloc[5 : 10]\n",
    "evaluation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ragas_dataset = prepare_ragas_dataset(evaluation_df)\n",
    "ragas_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import EvaluationDataset\n",
    "evaluation_dataset = EvaluationDataset.from_list(ragas_dataset)\n",
    "evaluation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(llm)\n",
    "metrics = [Faithfulness(), LLMContextRecall(), FactualCorrectness()]\n",
    "\n",
    "with tqdm(desc= 'Evaluating Queries') as pbar:\n",
    "    result = evaluate(dataset=evaluation_dataset,metrics=metrics,llm=evaluator_llm)\n",
    "    pbar.update(1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
